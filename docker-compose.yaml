version: "3"

services:

  bridge_srv:

    image: bridge_img
    container_name: bridge_cont
    build:
      # set the build context to the directory containing build files
      context: .
      dockerfile: bridge.Dockerfile
    # use the nvidia runtime for GPU access
    # uncomment to use nvidia drivers
    # runtime: nvidia
    environment:
      # pass the display variable to the container
      - DISPLAY=${DISPLAY}
      # enable NVIDIA GPU access inside the container
      - NVIDIA_DRIVER_CAPABILITIES=all
      - NVIDIA_VISIBLE_DEVICES=all
      # disable qt-X11 memory sharing for RViz
      - QT_X11_NO_MITSHM=1
      - ROS_IP=192.168.131.113
      - ROS_MASTER_URI=http://192.168.131.1:11311
    env_file:
      # set environment variables via a file
      - philbart.env
    security_opt:
    # this is set bc of errors with RViz being denied dbus comm w/ host
      - apparmor:unconfined
    volumes:
      # mount host directories to the container for persistent storage
      # - ../projects:/root/projects
      # mount the X11 socket to enable graphics display
      - /tmp/.X11-unix:/tmp/.X11-unix
      # required for non-nvidia users, comment out for nvidia users
      # - /dev/dri:/dev/dri
      # add the .Xauthority file to use ssh X11 forwarding
      - ${HOME}/.Xauthority:/root/.Xauthority:rw
    # give the container access to the host's network
    network_mode: host
    # enable stdin and tty to allow the user to run bash interactively
    stdin_open: true
    tty: true
    # add devices to the container
    # devices:
    #   - /dev/hokuyo:/dev/hokuyo
    #   - /dev/input/js0:/dev/input/js0
    # run the entrypoint script
    entrypoint: /bridge_entrypoint.sh
    # command: /bin/bash -c 'ros2 run ros1_bridge dynamic_bridge'
    